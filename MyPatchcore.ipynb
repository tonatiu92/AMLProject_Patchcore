{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c47ecf2",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ffd49",
   "metadata": {},
   "source": [
    "Here we store the libraries needed to run patchcore correctly including wich created by us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea2386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Modules\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import timm\n",
    "import time\n",
    "import utils\n",
    "import tqdm\n",
    "import sampler\n",
    "import patchcore as PatchcoreLib\n",
    "from numba import jit, cuda\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import os\n",
    "# Created Modules\n",
    "import data #load the dataset into data loader\n",
    "#import network as nn #load the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2b0d4",
   "metadata": {},
   "source": [
    "# GPU\n",
    "Checking GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c98f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc17da11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60698f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the device\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cde9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712d8f1",
   "metadata": {},
   "source": [
    "# Patchcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866dc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "RESIZE = 256\n",
    "IMAGESIZE = 224\n",
    "PATCHSIZE = 3\n",
    "PATCHSTRIDE = 1\n",
    "DILATION = 1\n",
    "PRETRAIN_EMBED = 1024\n",
    "TARGET_EMBED = 1024\n",
    "BATCH_SIZE = 1\n",
    "PERCENTAGE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ad5c8",
   "metadata": {},
   "source": [
    "## Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a461163b",
   "metadata": {},
   "source": [
    "- Loading the desired datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df3dba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = ['wood','zipper','toothbrush','metal_nut','screw','pill','transistor','tile','leather']\n",
    "datasets =  data.export_data(\".\\data\",selected_data, RESIZE, IMAGESIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49fe2cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wood': {'train': <data.Data at 0x24b4b48a1f0>,\n",
       "  'test': <data.Data at 0x24b4b48a2e0>},\n",
       " 'zipper': {'train': <data.Data at 0x24b4b435c70>,\n",
       "  'test': <data.Data at 0x24b59f2d3d0>},\n",
       " 'toothbrush': {'train': <data.Data at 0x24b59f2d760>,\n",
       "  'test': <data.Data at 0x24b59f2daf0>},\n",
       " 'metal_nut': {'train': <data.Data at 0x24b59f2de80>,\n",
       "  'test': <data.Data at 0x24b59f7b250>},\n",
       " 'screw': {'train': <data.Data at 0x24b59f7b5e0>,\n",
       "  'test': <data.Data at 0x24b59f7b970>},\n",
       " 'pill': {'train': <data.Data at 0x24b59f7bd00>,\n",
       "  'test': <data.Data at 0x24b59fb70d0>},\n",
       " 'transistor': {'train': <data.Data at 0x24b59fb7460>,\n",
       "  'test': <data.Data at 0x24b59fb77f0>},\n",
       " 'tile': {'train': <data.Data at 0x24b59fb7b80>,\n",
       "  'test': <data.Data at 0x24b59fb7f10>},\n",
       " 'leather': {'train': <data.Data at 0x24b59fec2e0>,\n",
       "  'test': <data.Data at 0x24b59fec670>}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec92fa",
   "metadata": {},
   "source": [
    "## 2. Autoencoder - ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aee767",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62ab72",
   "metadata": {},
   "source": [
    "- ResNetlike architecture with layers = {1,2,3,4}\n",
    "- Pathcore uses j and j + 1 layers\n",
    "- As we want mid-level features, we will use 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ccb508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In general for Resnet we use those layers.\n",
    "extract_layers = [2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bed9e8",
   "metadata": {},
   "source": [
    "### Timm Widereset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3a673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"wide_resnet50_2\"\n",
    "# We need to use timm because we will use pretrained dataset\n",
    "#Setting the resnet with out_indices that are our mid-level features\n",
    "neural_network = timm.create_model(name, out_indices = extract_layers, features_only = True, pretrained = True)\n",
    "neural_network.eval()\n",
    "neural_network = neural_network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee530bbf",
   "metadata": {},
   "source": [
    "### 3. Sampler Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ad31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter of the sampler\n",
    "sampling = sampler.Sampler(PERCENTAGE,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dc722",
   "metadata": {},
   "source": [
    "### Pathcore Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae3127f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patchcore = PatchcoreLib.Patchcore(neural_network,sampling,\n",
    "                                RESIZE,IMAGESIZE,PATCHSIZE,PATCHSTRIDE,DILATION,PRETRAIN_EMBED,TARGET_EMBED,\n",
    "                                device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fc5e2",
   "metadata": {},
   "source": [
    "### Fitting and testing Patchcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f58d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wood begin at \n",
      "--- 0.0009989738464355469 seconds ---\n",
      "wood fit end at \n",
      "--- 402.35060453414917 seconds ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit end at \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m----> 9\u001b[0m score_list[data] \u001b[38;5;241m=\u001b[39m \u001b[43mpatchcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m end at \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Thomas\\PoliTo\\Advanced Machine Learning\\AML_Project\\Patchcore\\patchcore.py:69\u001b[0m, in \u001b[0;36mPatchcore.predict\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    For clip features\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     features_map \u001b[38;5;241m=\u001b[39m [features_map[layer] \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m features_map ]\n\u001b[1;32m---> 69\u001b[0m features, nb_patch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_patch_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m neareset_neighbours_index, new_feature, maximum_score_value, min_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximum_distance_score(features, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory_bank)\n\u001b[0;32m     73\u001b[0m final_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincreasing_score(neareset_neighbours_index,new_feature, features,maximum_score_value)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Thomas\\PoliTo\\Advanced Machine Learning\\AML_Project\\Patchcore\\patchcore.py:106\u001b[0m, in \u001b[0;36mPatchcore.local_patch_features\u001b[1;34m(self, image, device)\u001b[0m\n\u001b[0;32m    103\u001b[0m features \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m#PART 3 Re-Scaling the features to improve resolution and match both patch features collections\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m features[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling_to_low_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m features \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m#Preprocessing (1) or (3) in the Article for each feature\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Thomas\\PoliTo\\Advanced Machine Learning\\AML_Project\\Patchcore\\patchcore.py:159\u001b[0m, in \u001b[0;36mPatchcore.scaling_to_low_level\u001b[1;34m(self, input, patch_shapes)\u001b[0m\n\u001b[0;32m    156\u001b[0m _features \u001b[38;5;241m=\u001b[39m _features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m#bilinear interpolation to improve the resolution (add dimension for the tensor in order to get 4-D tensor)\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m _features \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbilinear_interpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_shapes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_shapes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#output to lowest hierarchy level feature\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m#remove the dim 1 added during interpolation\u001b[39;00m\n\u001b[0;32m    162\u001b[0m _features \u001b[38;5;241m=\u001b[39m _features\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Thomas\\PoliTo\\Advanced Machine Learning\\AML_Project\\Patchcore\\utils.py:52\u001b[0m, in \u001b[0;36mbilinear_interpolate\u001b[1;34m(inputs, output_size)\u001b[0m\n\u001b[0;32m     49\u001b[0m         w4 \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m*\u001b[39m height_scale \u001b[38;5;241m-\u001b[39m x1) \u001b[38;5;241m*\u001b[39m (j \u001b[38;5;241m*\u001b[39m width_scale \u001b[38;5;241m-\u001b[39m y1)\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;66;03m# Perform the interpolation\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m         output[:, :, i, j] \u001b[38;5;241m=\u001b[39m w1 \u001b[38;5;241m*\u001b[39m inputs[:, :, x1, y1] \u001b[38;5;241m+\u001b[39m w2 \u001b[38;5;241m*\u001b[39m inputs[:, :, x1, y2] \u001b[38;5;241m+\u001b[39m w3 \u001b[38;5;241m*\u001b[39m inputs[:, :, x2, y1] \u001b[38;5;241m+\u001b[39m w4 \u001b[38;5;241m*\u001b[39m inputs[:, :, x2, y2]\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score_list = {}\n",
    "for data in datasets:\n",
    "    print(f\"{data} begin at \")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    patchcore.fit(datasets[data][\"train\"].dataloader)\n",
    "    print(f\"{data} fit end at \")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    score_list[data] = patchcore.predict(datasets[data][\"test\"].dataloader)\n",
    "    print(f\"{data} end at \")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f2da4",
   "metadata": {},
   "source": [
    "### Analysis of patchcore scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf08d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = dict.fromkeys(selected_data, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa71723",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in datasets:\n",
    "    \n",
    "    print(f\"--------RESULTS FOR {data}-----------\")\n",
    "    label =[1 if x[\"score\"][1][0]!=\"good\" else 0 for x in score_list[data]]\n",
    "    preds = [x[\"score\"][0].to(\"cpu\") for x in score_list[data]]\n",
    "    label = np.stack(label)\n",
    "    preds = np.stack(preds)\n",
    "    stat[data][\"roc_auc\"] = roc_auc_score(label, preds)\n",
    "    print(f\"roc_auc score: {stat[data]['roc_auc']}\")\n",
    "    print(f\"We obtain the following plot: \")\n",
    "    utils.ROC(label, preds, data)\n",
    "    image_paths = [os.path.join(\".\\data\",f\"{data}\",\"test\",x[0],x[1]) for x in datasets[data][\"test\"].dataloader.dataset.data_to_iterate]\n",
    "    mask_paths = [x[2] for x in datasets[data][\"test\"].dataloader.dataset.data_to_iterate]\n",
    "    image_save_path = f\".\\\\data\\\\{data}\\\\segmentation\"\n",
    "    os.makedirs(image_save_path, exist_ok = True)\n",
    "    mask_list = [x[\"mask\"][0].to(\"cpu\") for x in score_list[data]]\n",
    "    utils.plot_segmentation_images(datasets,data,image_save_path,image_paths,mask_list,preds,mask_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79962e6e",
   "metadata": {},
   "source": [
    "## Training on different k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = {1:[],2:[],3:[],4:[],5:[]}\n",
    "start_time = time.time()\n",
    "score_list2 = {}\n",
    "for k in range(2,6):\n",
    "    \n",
    "    \n",
    "    patchcore = PatchcoreLib.Patchcore(neural_network,sampling,\n",
    "                                    RESIZE,IMAGESIZE,PATCHSIZE,PATCHSTRIDE,DILATION,PRETRAIN_EMBED,TARGET_EMBED,\n",
    "                                    device,k)\n",
    "    for data in datasets:\n",
    "        print(f\"{data} begin at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        patchcore.fit(datasets[data][\"train\"].dataloader)\n",
    "        print(f\"{data} fit end at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        score_list2[data] = patchcore.predict(datasets[data][\"test\"].dataloader)\n",
    "        print(f\"{data} end at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    for data in datasets:\n",
    "        print(f\"--------RESULTS FOR {data}-----------\")\n",
    "        label =[1 if x[\"score\"][1][0]!=\"good\" else 0 for x in score_list2[data]]\n",
    "        preds = [x[\"score\"][0].to(\"cpu\") for x in score_list2[data]]\n",
    "        label = np.stack(label)\n",
    "        preds = np.stack(preds)\n",
    "        d_k[k].append(roc_auc_score(label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('k_2.txt','w') as f:\n",
    "    f.write('dict = ' + str(d_k) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50657881",
   "metadata": {},
   "source": [
    "## Training on different Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851bf16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wood begin at \n",
      "--- 0.0005345344543457031 seconds ---\n"
     ]
    }
   ],
   "source": [
    "d_percentage = {str(0.1):[],str(0.25):[],str(0.5):[],str(1):[]}\n",
    "start_time = time.time()\n",
    "score_list2 = {}\n",
    "for per in [1]:\n",
    "    torch.cuda.empty_cache()\n",
    "    sampling = sampler.Sampler(per,device)\n",
    "    patchcore = PatchcoreLib.Patchcore(neural_network,sampling,\n",
    "                                    RESIZE,IMAGESIZE,PATCHSIZE,PATCHSTRIDE,DILATION,PRETRAIN_EMBED,TARGET_EMBED,\n",
    "                                    device)\n",
    "    for data in datasets:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"{data} begin at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        patchcore.fit(datasets[data][\"train\"].dataloader)\n",
    "        print(f\"{data} fit end at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        score_list2[data] = patchcore.predict(datasets[data][\"test\"].dataloader)\n",
    "        print(f\"{data} end at \")\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    for data in datasets:\n",
    "        print(f\"--------RESULTS FOR {data}-----------\")\n",
    "        label =[1 if x[\"score\"][1][0]!=\"good\" else 0 for x in score_list2[data]]\n",
    "        preds = [x[\"score\"][0].to(\"cpu\") for x in score_list2[data]]\n",
    "        label = np.stack(label)\n",
    "        preds = np.stack(preds)\n",
    "        d_percentage[str(per)].append(roc_auc_score(label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('percentage_3.txt','w') as f:\n",
    "    f.write('dict = ' + str(d_percentage) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e9507c",
   "metadata": {},
   "source": [
    "### Plotting Hyperparameters Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c018b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
